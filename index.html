<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <link rel="manifest" href="manifest.json">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>EVN Safety AI v2.21</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <style>
        body { margin: 0; background: #000; color: #fff; font-family: sans-serif; overflow: hidden; }
        #container { position: relative; width: 100vw; height: 100vh; }
        video, canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; }
        .ui-overlay { position: absolute; top: 10px; width: 100%; z-index: 10; text-align: center; }
        #status { background: rgba(0,0,0,0.6); padding: 8px 15px; border-radius: 20px; font-size: 14px; }
        .warning-flash { animation: flash 0.5s infinite; color: #ff0000; font-weight: bold; display: none; }
        @keyframes flash { 50% { opacity: 0; } }
    </style>
</head>
<body>

<div id="container">
    <video id="video" autoplay playsinline muted></video>
    <canvas id="canvas"></canvas>
    
    <div class="ui-overlay">
        <span id="status">‚è≥ ƒêang n·∫°p m√¥ h√¨nh AI...</span>
        <div id="warning" class="warning-flash">‚ö†Ô∏è PH√ÅT HI·ªÜN VI PH·∫†M PPE!</div>
    </div>
</div>

<audio id="alarm" src="bip.mp3" preload="auto"></audio>

<script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const status = document.getElementById('status');
    const warning = document.getElementById('warning');
    const alarm = document.getElementById('alarm');

    let session;

    // 1. Kh·ªüi t·∫°o Camera
    async function initCamera() {
        const stream = await navigator.mediaDevices.getUserMedia({
            video: { facingMode: "environment", width: 640, height: 640 }
        });
        video.srcObject = stream;
        return new Promise(resolve => video.onloadedmetadata = resolve);
    }

    // 2. N·∫°p m√¥ h√¨nh AI (.onnx)
    async function initAI() {
        try {
            // N·∫°p file best.onnx (ƒë√£ convert t·ª´ best.pt)
            session = await ort.InferenceSession.create('./best.onnx');
            status.innerText = "üü¢ AI S·∫¥N S√ÄNG - ƒêANG QU√âT";
            runInference();
        } catch (e) {
            status.innerText = "‚ùå L·ªói n·∫°p m√¥ h√¨nh: " + e.message;
        }
    }

    // 3. Ch·∫°y nh·∫≠n di·ªán realtime
    async function runInference() {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        // V·∫Ω video l√™n canvas ƒë·ªÉ l·∫•y d·ªØ li·ªáu pixel
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        
        // Ghi ch√∫: ·ªû ƒë√¢y c·∫ßn c√°c b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω Tensor (Resize 640x640, Normalize)
        // V√¨ gi·ªõi h·∫°n tr√¨nh duy·ªát, ta s·∫Ω qu√©t ƒë∆°n gi·∫£n ho·∫∑c d√πng th∆∞ vi·ªán Ultralytics JS
        
        // Gi·∫£ l·∫≠p ph√°t hi·ªán vi ph·∫°m (v√≠ d·ª•: n·∫øu class_id = 2 ho·∫∑c 4 nh∆∞ data c·ªßa b·∫°n)
        let violationDetected = false; 

        if (violationDetected) {
            warning.style.display = "block";
            alarm.play(); // Ph√°t ti·∫øng b√≠p
        } else {
            warning.style.display = "none";
        }

        requestAnimationFrame(runInference);
    }

    // Ch·∫°y h·ªá th·ªëng
    initCamera().then(initAI);

    // ƒêƒÉng k√Ω Service Worker cho PWA
    if ('serviceWorker' in navigator) {
        navigator.serviceWorker.register('sw.js');
    }
</script>
</body>
</html>
